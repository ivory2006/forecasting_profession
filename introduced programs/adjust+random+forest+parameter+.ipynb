{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/users/u1037466/.local/lib/python3.6/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "#-multibars,Author:ssb--\n",
    "from sklearn import metrics, cross_validation\n",
    "from sklearn import datasets\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score,precision_score,recall_score,f1_score,classification_report,confusion_matrix\n",
    "import pandas as pd\n",
    "from pprint import pprint\n",
    "from sklearn.model_selection import train_test_split,cross_val_score\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "df=pd.read_csv('number_more_new200k_250.csv')\n",
    "#df=pd.read_csv('sparseautoencoderResults.csv')\n",
    "#samples=df.loc[:,['Openness','Conscientousness','Extraversion','Agreeableness','Emotional_Range','Conversation','Openness to Change','Hedonism','Self-enhancement','Self-transcendence']]\n",
    "samples=df.loc[:,['consumption_preferences_automobile_safety','consumption_preferences_clothes_quality','consumption_preferences_clothes_style','consumption_preferences_clothes_comfort','consumption_preferences_influence_brand_name','consumption_preferences_influence_utility','consumption_preferences_influence_online_ads','consumption_preferences_influence_social_media','consumption_preferences_influence_family_members','consumption_preferences_spur_of_moment','consumption_preferences_credit_card_payment','consumption_preferences_eat_out','consumption_preferences_gym_membership','consumption_preferences_outdoor','consumption_preferences_concerned_environment','consumption_preferences_start_business','consumption_preferences_movie_romance','consumption_preferences_movie_adventure','consumption_preferences_movie_horror','consumption_preferences_movie_musical','consumption_preferences_movie_historical','consumption_preferences_movie_science_fiction','consumption_preferences_movie_war','consumption_preferences_movie_drama','consumption_preferences_movie_action','consumption_preferences_movie_documentary','consumption_preferences_music_rap','consumption_preferences_music_country','consumption_preferences_music_r_b','consumption_preferences_music_hip_hop','consumption_preferences_music_live_event','consumption_preferences_music_playing','consumption_preferences_music_latin','consumption_preferences_music_rock','consumption_preferences_music_classical','consumption_preferences_read_frequency','consumption_preferences_books_entertainment_magazines','consumption_preferences_books_non_fiction','consumption_preferences_books_financial_investing','consumption_preferences_books_autobiographies','consumption_preferences_volunteer','Challenge','need_challenge','Closeness','need_closeness','Curiosity','need_curiosity','Excitement','need_excitement','Harmony','need_harmony','Ideal','need_ideal','Liberty','need_liberty','Love','need_love','Practicality','need_practicality','Self-expression','need_self_expression','Stability','need_stability','Structure','need_structure','Adventurousness','facet_adventurousness','Artistic interests','facet_artistic_interests','Emotionality','facet_emotionality','Imagination','facet_imagination','Intellect','facet_intellect','Authority-challenging','facet_liberalism','Openness','big5_openness','Achievement striving','facet_achievement_striving','Cautiousness','facet_cautiousness','Dutifulness','facet_dutifulness','Orderliness','facet_orderliness','Self-discipline','facet_self_discipline','Self-efficacy','facet_self_efficacy','Conscientiousness','big5_conscientiousness','Activity level','facet_activity_level','Assertiveness','facet_assertiveness','Cheerfulness','facet_cheerfulness','Excitement-seeking','facet_excitement_seeking','Outgoing','facet_friendliness','Gregariousness','facet_gregariousness','Extraversion','big5_extraversion','Altruism','facet_altruism','Cooperation','facet_cooperation','Modesty','facet_modesty','Uncompromising','facet_morality','Sympathy','facet_sympathy','Trust','facet_trust','Agreeableness','big5_agreeableness','Emotional range','big5_neuroticism','Conservation','value_conservation','Openness to change','value_openness_to_change','Hedonism','value_hedonism','Self-enhancement','value_self_enhancement','Self-transcendence','value_self_transcendence']]\n",
    "\n",
    "target=df.loc[:,'Profession']\n",
    "#cv_folds = cross_validation.StratifiedKFold(target, n_folds=5, shuffle=False, random_state=0)\n",
    "samples_train,samples_test,target_train,target_test = train_test_split(samples,target,test_size=0.2,random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the logistic accuracy score is 0.219771405655\n",
      "the Logistic precision is 0.2\n",
      "the Logistic recall is 0.22\n",
      "the Logistic f1score is 0.2 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "classifier_SL=LogisticRegression().fit(samples_train,target_train) \n",
    "target_pred_SL=classifier_SL.predict(samples_test) \n",
    "accuracy_SL=accuracy_score(target_test,target_pred_SL) \n",
    "report_SL=classification_report(target_test,target_pred_SL)\n",
    "lines_SL = report_SL.split('\\n')\n",
    "NewLines_SL=lines_SL[74].split(' ')\n",
    "Logistic_precision_SL=float(NewLines_SL[9])\n",
    "Logistic_recall_SL=float(NewLines_SL[15])\n",
    "Logistic_f1score_SL=float(NewLines_SL[21])\n",
    "print ('the logistic accuracy score is',accuracy_SL)\n",
    "print(\"the Logistic precision is\",Logistic_precision_SL)\n",
    "print(\"the Logistic recall is\",Logistic_recall_SL)\n",
    "print(\"the Logistic f1score is\",Logistic_f1score_SL,'\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/users/u1037466/.local/lib/python3.6/site-packages/sklearn/ensemble/forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "/home/users/u1037466/.local/lib/python3.6/site-packages/sklearn/ensemble/forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "__init__() got an unexpected keyword argument 'param_grid'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-06a88b4312f0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0mparam_test1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'n_estimators'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m40\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m60\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m70\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m \u001b[0mgsearch1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mOneVsRestClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mRandomForestClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmin_samples_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmin_samples_leaf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmax_depth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmax_features\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'sqrt'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mparam_grid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparam_test1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'roc_auc'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m \u001b[0mgsearch1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msamples_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtarget_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgsearch1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrid_scores_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgsearch1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_params_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgsearch1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_score_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: __init__() got an unexpected keyword argument 'param_grid'"
     ]
    }
   ],
   "source": [
    "#randomforest\n",
    "\n",
    "from sklearn import metrics, cross_validation\n",
    "from sklearn import datasets\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score,precision_score,recall_score,f1_score,classification_report,confusion_matrix\n",
    "import pandas as pd\n",
    "from pprint import pprint\n",
    "from sklearn.model_selection import train_test_split,cross_val_score\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "df=pd.read_csv('number_more_new200k_250.csv')\n",
    "samples=df.loc[:,['consumption_preferences_automobile_safety','consumption_preferences_clothes_quality','consumption_preferences_clothes_style','consumption_preferences_clothes_comfort','consumption_preferences_influence_brand_name','consumption_preferences_influence_utility','consumption_preferences_influence_online_ads','consumption_preferences_influence_social_media','consumption_preferences_influence_family_members','consumption_preferences_spur_of_moment','consumption_preferences_credit_card_payment','consumption_preferences_eat_out','consumption_preferences_gym_membership','consumption_preferences_outdoor','consumption_preferences_concerned_environment','consumption_preferences_start_business','consumption_preferences_movie_romance','consumption_preferences_movie_adventure','consumption_preferences_movie_horror','consumption_preferences_movie_musical','consumption_preferences_movie_historical','consumption_preferences_movie_science_fiction','consumption_preferences_movie_war','consumption_preferences_movie_drama','consumption_preferences_movie_action','consumption_preferences_movie_documentary','consumption_preferences_music_rap','consumption_preferences_music_country','consumption_preferences_music_r_b','consumption_preferences_music_hip_hop','consumption_preferences_music_live_event','consumption_preferences_music_playing','consumption_preferences_music_latin','consumption_preferences_music_rock','consumption_preferences_music_classical','consumption_preferences_read_frequency','consumption_preferences_books_entertainment_magazines','consumption_preferences_books_non_fiction','consumption_preferences_books_financial_investing','consumption_preferences_books_autobiographies','consumption_preferences_volunteer','Challenge','need_challenge','Closeness','need_closeness','Curiosity','need_curiosity','Excitement','need_excitement','Harmony','need_harmony','Ideal','need_ideal','Liberty','need_liberty','Love','need_love','Practicality','need_practicality','Self-expression','need_self_expression','Stability','need_stability','Structure','need_structure','Adventurousness','facet_adventurousness','Artistic interests','facet_artistic_interests','Emotionality','facet_emotionality','Imagination','facet_imagination','Intellect','facet_intellect','Authority-challenging','facet_liberalism','Openness','big5_openness','Achievement striving','facet_achievement_striving','Cautiousness','facet_cautiousness','Dutifulness','facet_dutifulness','Orderliness','facet_orderliness','Self-discipline','facet_self_discipline','Self-efficacy','facet_self_efficacy','Conscientiousness','big5_conscientiousness','Activity level','facet_activity_level','Assertiveness','facet_assertiveness','Cheerfulness','facet_cheerfulness','Excitement-seeking','facet_excitement_seeking','Outgoing','facet_friendliness','Gregariousness','facet_gregariousness','Extraversion','big5_extraversion','Altruism','facet_altruism','Cooperation','facet_cooperation','Modesty','facet_modesty','Uncompromising','facet_morality','Sympathy','facet_sympathy','Trust','facet_trust','Agreeableness','big5_agreeableness','Emotional range','big5_neuroticism','Conservation','value_conservation','Openness to change','value_openness_to_change','Hedonism','value_hedonism','Self-enhancement','value_self_enhancement','Self-transcendence','value_self_transcendence']]\n",
    "target=df.loc[:,'Profession']\n",
    "#cv_folds = cross_validation.StratifiedKFold(target, n_folds=5, shuffle=False, random_state=0)\n",
    "samples_train,samples_test,target_train,target_test = train_test_split(samples,target,test_size=0.2,random_state=0)\n",
    "from sklearn.ensemble import RandomForestClassifier,AdaBoostClassifier\n",
    "RF=RandomForestClassifier(oob_score=True, random_state=10)\n",
    "RF_train=RF.fit(samples_train,target_train)\n",
    "target_pred_SL_R=RF_train.predict(samples_test) #testing dataset\n",
    "accuracy_SL_R=accuracy_score(target_test,target_pred_SL_R) #accuracy rate\n",
    "randomforest_report=classification_report(target_test,target_pred_SL_R) #report\n",
    "lines_RF = randomforest_report.split('\\n')\n",
    "NewLines_RF=lines_RF[74].split(' ')\n",
    "\n",
    "#RF框架参数\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "target_train = label_binarize(target_train, classes=[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70])\n",
    "param_test1 = {'n_estimators':[10,20,30,40,50,60,70]}\n",
    "gsearch1 = GridSearchCV(estimator = RandomForestClassifier(min_samples_split=100,min_samples_leaf=20,max_depth=8,max_features='sqrt',random_state=10),param_grid = param_test1, scoring='roc_auc',cv=5)\n",
    "gsearch1.fit(samples_train,target_train)\n",
    "print(gsearch1.grid_scores_, gsearch1.best_params_, gsearch1.best_score_)\n",
    "\n",
    "\n",
    "Logistic_precision_RF=float(NewLines_RF[9])\n",
    "Logistic_recall_RF=float(NewLines_RF[15])\n",
    "Logistic_f1score_RF=float(NewLines_RF[21])\n",
    "print (\"the oob_score\",RF_train.oob_score_)\n",
    "print ('the RF accuracy score is',accuracy_SL_R)\n",
    "print(\"the RF precision is\",Logistic_precision_RF)\n",
    "print(\"the RF recall is\",Logistic_recall_RF)\n",
    "print(\"the RF f1score is\",Logistic_f1score_RF,'\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the oob_score 0.893240046308\n",
      "the RF accuracy score is 0.940809341655\n",
      "the RF precision is 0.94\n",
      "the RF recall is 0.94\n",
      "the RF f1score is 0.94 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/users/u1037466/.local/lib/python3.6/site-packages/sklearn/ensemble/forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "/home/users/u1037466/.local/lib/python3.6/site-packages/sklearn/ensemble/forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n"
     ]
    }
   ],
   "source": [
    "#smote+motek+randomforest\n",
    "#-multibars,Author:ssb--\n",
    "from sklearn import metrics, cross_validation\n",
    "from sklearn import datasets\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score,precision_score,recall_score,f1_score,classification_report,confusion_matrix\n",
    "import pandas as pd\n",
    "from pprint import pprint\n",
    "from sklearn.model_selection import train_test_split,cross_val_score\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "df=pd.read_csv('more_smote_tomek1.csv')\n",
    "#df=pd.read_csv('sparseautoencoderResults.csv')\n",
    "#samples=df.loc[:,['f1','f2','f3','f4','f5','f6','f7','f8','f9','f10']]\n",
    "samples=df.loc[:,['need_challenge','Closeness','need_closeness','Curiosity','need_curiosity','Excitement','need_excitement','Harmony','need_harmony','Ideal','need_ideal','Liberty','need_liberty','Love','need_love','Practicality','need_practicality','Self-expression','need_self_expression','Stability','need_stability','Structure','need_structure','Adventurousness','facet_adventurousness','Artistic interests','facet_artistic_interests','Emotionality','facet_emotionality','Imagination','facet_imagination','Intellect','facet_intellect','Authority-challenging','facet_liberalism','Openness','big5_openness','Achievement striving','facet_achievement_striving','Cautiousness','facet_cautiousness','Dutifulness','facet_dutifulness','Orderliness','facet_orderliness','Self-discipline','facet_self_discipline','Self-efficacy','facet_self_efficacy','Conscientiousness','big5_conscientiousness','Activity level','facet_activity_level','Assertiveness','facet_assertiveness','Cheerfulness','facet_cheerfulness','Excitement-seeking','facet_excitement_seeking','Outgoing','facet_friendliness','Gregariousness','facet_gregariousness','Extraversion','big5_extraversion','Altruism','facet_altruism','Cooperation','facet_cooperation','Modesty','facet_modesty','Uncompromising','facet_morality','Sympathy','facet_sympathy','Trust','facet_trust','Agreeableness','big5_agreeableness','Emotional range','big5_neuroticism','Conservation','value_conservation','Openness to change','value_openness_to_change','Hedonism','value_hedonism','Self-enhancement','value_self_enhancement','Self-transcendence','value_self_transcendence']]\n",
    "#samples=df.loc[:,[\"f1\",\"f2\",\"f3\",\"f4\",\"f5\",\"f6\",\"f7\",\"f8\",\"f9\",\"f10\",\"f11\",\"f12\",\"f13\",\"f14\",\"f15\",\"f16\",\"f17\",\"f18\",\"f19\",\"f20\",\"f21\",\"f22\",\"f23\",\"f24\",\"f25\",\"f26\",\"f27\",\"f28\",\"f29\",\"f30\",\"f31\",\"f32\",\"f33\",\"f34\",\"f35\",\"f36\",\"f37\",\"f38\",\"f39\",\"f40\",\"f41\",\"f42\",\"f43\",\"f44\",\"f45\",\"f46\",\"f47\",\"f48\",\"f49\",\"f50\",\"f51\",\"f52\",\"f53\",\"f54\",\"f55\",\"f56\",\"f57\",\"f58\",\"f59\",\"f60\",\"f61\",\"f62\",\"f63\",\"f64\",\"f65\",\"f66\",\"f67\",\"f68\",\"f69\",\"f70\",\"f71\",\"f72\",\"f73\",\"f74\",\"f75\",\"f76\",\"f77\",\"f78\",\"f79\",\"f80\",\"f81\",\"f82\",\"f83\",\"f84\",\"f85\",\"f86\",\"f87\",\"f88\",\"f89\",\"f90\",\"f91\",\"f92\",\"f93\",\"f94\",\"f95\",\"f96\",\"f97\",\"f98\",\"f99\",\"f100\",\"f101\",\"f102\",\"f103\",\"f104\",\"f105\",\"f106\",\"f107\",\"f108\",\"f109\",\"f110\",\"f111\",\"f112\",\"f113\",\"f114\",\"f115\",\"f116\",\"f117\",\"f118\",\"f119\",\"f120\",\"f121\",\"f122\",\"f123\",\"f124\",\"f125\",\"f126\",\"f127\",\"f128\",\"f129\",\"f130\",\"f131\",\"f132\",\"Profession\"]]\n",
    "   \n",
    "target=df.loc[:,'Profession']\n",
    "#cv_folds = cross_validation.StratifiedKFold(target, n_folds=5, shuffle=False, random_state=0)\n",
    "samples_train,samples_test,target_train,target_test = train_test_split(samples,target,test_size=0.2,random_state=0)\n",
    "from sklearn.ensemble import RandomForestClassifier,AdaBoostClassifier\n",
    "RF=RandomForestClassifier(oob_score=True, random_state=10)\n",
    "RF_train=RF.fit(samples_train,target_train)\n",
    "target_pred_SL_R=RF_train.predict(samples_test) #testing dataset\n",
    "accuracy_SL_R=accuracy_score(target_test,target_pred_SL_R) #accuracy rate\n",
    "randomforest_report=classification_report(target_test,target_pred_SL_R) #report\n",
    "lines_RF = randomforest_report.split('\\n')\n",
    "NewLines_RF=lines_RF[74].split(' ')\n",
    "\n",
    "# print(NewLines_RF)\n",
    "# #pprint(lines_RF)\n",
    "Logistic_precision_RF=float(NewLines_RF[9])\n",
    "Logistic_recall_RF=float(NewLines_RF[15])\n",
    "Logistic_f1score_RF=float(NewLines_RF[21])\n",
    "print (\"the oob_score\",RF_train.oob_score_)\n",
    "print ('the RF accuracy score is',accuracy_SL_R)\n",
    "print(\"the RF precision is\",Logistic_precision_RF)\n",
    "print(\"the RF recall is\",Logistic_recall_RF)\n",
    "print(\"the RF f1score is\",Logistic_f1score_RF,'\\n')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sparseautoencoder+ smote+motek+randomforest\n",
    "#-multibars,Author:ssb--\n",
    "from sklearn import metrics, cross_validation\n",
    "from sklearn import datasets\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score,precision_score,recall_score,f1_score,classification_report,confusion_matrix\n",
    "import pandas as pd\n",
    "from pprint import pprint\n",
    "from sklearn.model_selection import train_test_split,cross_val_score\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "df=pd.read_csv('sparseautoencoderResults_moredata1.csv')\n",
    "\n",
    "samples=df.loc[:,[\"f1\",\"f2\",\"f3\",\"f4\",\"f5\",\"f6\",\"f7\",\"f8\",\"f9\",\"f10\",\"f11\",\"f12\",\"f13\",\"f14\",\"f15\",\"f16\",\"f17\",\"f18\",\"f19\",\"f20\",\"f21\",\"f22\",\"f23\",\"f24\",\"f25\",\"f26\",\"f27\",\"f28\",\"f29\",\"f30\",\"f31\",\"f32\",\"f33\",\"f34\",\"f35\",\"f36\",\"f37\",\"f38\",\"f39\",\"f40\",\"f41\",\"f42\",\"f43\",\"f44\",\"f45\",\"f46\",\"f47\",\"f48\",\"f49\",\"f50\",\"f51\",\"f52\",\"f53\",\"f54\",\"f55\",\"f56\",\"f57\",\"f58\",\"f59\",\"f60\",\"f61\",\"f62\",\"f63\",\"f64\",\"f65\",\"f66\",\"f67\",\"f68\",\"f69\",\"f70\",\"f71\",\"f72\",\"f73\",\"f74\",\"f75\",\"f76\",\"f77\",\"f78\",\"f79\",\"f80\",\"f81\",\"f82\",\"f83\",\"f84\",\"f85\",\"f86\",\"f87\",\"f88\",\"f89\",\"f90\",\"f91\",\"f92\",\"f93\",\"f94\",\"f95\",\"f96\",\"f97\",\"f98\",\"f99\",\"f100\",\"f101\",\"f102\",\"f103\",\"f104\",\"f105\",\"f106\",\"f107\",\"f108\",\"f109\",\"f110\",\"f111\",\"f112\",\"f113\",\"f114\",\"f115\",\"f116\",\"f117\",\"f118\",\"f119\",\"f120\",\"f121\",\"f122\",\"f123\",\"f124\",\"f125\",\"f126\",\"f127\",\"f128\",\"f129\",\"f130\",\"f131\",\"f132\",\"Profession\"]]\n",
    "   \n",
    "target=df.loc[:,'Profession']\n",
    "\n",
    "#cv_folds = cross_validation.StratifiedKFold(target, n_folds=5, shuffle=False, random_state=0)\n",
    "samples_train,samples_test,target_train,target_test = train_test_split(samples,target,test_size=0.2,random_state=0)\n",
    "from sklearn.ensemble import RandomForestClassifier,AdaBoostClassifier\n",
    "# RF= RandomForestClassifier(oob_score=True, random_state=10)\n",
    "# RF_train=RF.fit(samples_train,target_train)\n",
    "# target_pred_SL_R=RF_train.predict(samples_test) #testing dataset\n",
    "# accuracy_SL_R=accuracy_score(target_test,target_pred_SL_R) #accuracy rate\n",
    "# randomforest_report=classification_report(target_test,target_pred_SL_R) #report\n",
    "# lines_RF = randomforest_report.split('\\n')\n",
    "# NewLines_RF=lines_RF[74].split(' ')\n",
    "\n",
    "#RF框架参数\n",
    "#estimators\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "target_train = label_binarize(target_train, classes=[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70])\n",
    "# param_test1 = {'n_estimators':[10,20,30,40,50,60,70,80,90,100]}\n",
    "# #gsearch1 = GridSearchCV(estimator = RandomForestClassifier(min_samples_split=100,min_samples_leaf=20,max_depth=8,max_features='sqrt',random_state=10),param_grid = param_test1, scoring='roc_auc',cv=5)\n",
    "# gsearch1 = GridSearchCV(estimator = RandomForestClassifier(random_state=10,oob_score=True),param_grid = param_test1, scoring='roc_auc',cv=5)\n",
    "\n",
    "# gsearch1.fit(samples_train,target_train)\n",
    "# print(gsearch1.grid_scores_, gsearch1.best_params_, gsearch1.best_score_)\n",
    "\n",
    "#max_depth\n",
    "# param_test2 = {'max_depth':[10,12,14,16,18,20], 'min_samples_split':[10,30,50,70,90,110]}\n",
    "# gsearch2 = GridSearchCV(estimator = RandomForestClassifier(n_estimators= 90,min_samples_leaf=20,max_features='sqrt' ,oob_score=True, random_state=10),param_grid = param_test2, scoring='roc_auc',iid=False, cv=5)\n",
    "# gsearch2.fit(samples_train,target_train)\n",
    "# print(gsearch2.grid_scores_, gsearch2.best_params_, gsearch2.best_score_)\n",
    "\n",
    "param_test3 = {'min_samples_split':[10,30,50,70,90,110], 'min_samples_leaf':[10,20,30,40,50,60,70,80]}\n",
    "gsearch3 = GridSearchCV(estimator = RandomForestClassifier(n_estimators= 90, max_depth=14,max_features='sqrt' ,oob_score=True, random_state=10),param_grid = param_test3, scoring='roc_auc',iid=False, cv=5)\n",
    "gsearch2.fit(samples_train,target_train)\n",
    "print(gsearch3.grid_scores_, gsearch3.best_params_, gsearch3.best_score_)\n",
    "\n",
    "# Logistic_precision_RF=float(NewLines_RF[9])\n",
    "# Logistic_recall_RF=float(NewLines_RF[15])\n",
    "# Logistic_f1score_RF=float(NewLines_RF[21])\n",
    "# print (\"the oob_score\",RF_train.oob_score_)\n",
    "# print ('the RF accuracy score is',accuracy_SL_R)\n",
    "# print(\"the RF precision is\",Logistic_precision_RF)\n",
    "# print(\"the RF recall is\",Logistic_recall_RF)\n",
    "# print(\"the RF f1score is\",Logistic_f1score_RF,'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the AD accuracy score is 0.0465209544817\n",
      "the AD precision is 0.09\n",
      "the AD recall is 0.05\n",
      "the AD f1score is 0.03 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/users/u1037466/.local/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "#AdaBoostClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "classifier_AD=OneVsRestClassifier(AdaBoostClassifier().fit(samples_train,target_train)) #onevsrest \n",
    "target_pred_AD=classifier_AD.predict(samples_test) \n",
    "accuracy_AD=accuracy_score(target_test,target_pred_AD) \n",
    "report_AD=classification_report(target_test,target_pred_AD)\n",
    "lines_AD = report_AD.split('\\n')\n",
    "NewLines_AD=lines_AD[74].split(' ')\n",
    "Logistic_precision_AD=float(NewLines_AD[9])\n",
    "Logistic_recall_AD=float(NewLines_AD[15])\n",
    "Logistic_f1score_AD=float(NewLines_AD[21])\n",
    "print ('the AD accuracy score is',accuracy_AD)\n",
    "print(\"the AD precision is\",Logistic_precision_AD)\n",
    "print(\"the AD recall is\",Logistic_recall_AD)\n",
    "print(\"the AD f1score is\",Logistic_f1score_AD,'\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the NB accuracy score is 0.0759975937437\n",
      "the NB precision is 0.11\n",
      "the NB recall is 0.08\n",
      "the NB f1score is 0.05 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/users/u1037466/.local/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "#NaiveBays\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "classifier_NB=OneVsRestClassifier(GaussianNB().fit(samples_train,target_train)) #onevsrest\n",
    "target_pred_NB=classifier_NB.predict(samples_test) \n",
    "accuracy_NB=accuracy_score(target_test,target_pred_NB) \n",
    "report_NB=classification_report(target_test,target_pred_NB)\n",
    "lines_NB = report_NB.split('\\n')\n",
    "NewLines_NB=lines_NB[74].split(' ')\n",
    "Logistic_precision_NB=float(NewLines_NB[9])\n",
    "Logistic_recall_NB=float(NewLines_NB[15])\n",
    "Logistic_f1score_NB=float(NewLines_NB[21])\n",
    "print ('the NB accuracy score is',accuracy_NB)\n",
    "print(\"the NB precision is\",Logistic_precision_NB)\n",
    "print(\"the NB recall is\",Logistic_recall_NB)\n",
    "print(\"the NB f1score is\",Logistic_f1score_NB,'\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the SVC accuracy score is 0.125125325847\n",
      "the SVC precision is 0.13\n",
      "the SVC recall is 0.13\n",
      "the SVC f1score is 0.09 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/users/u1037466/.local/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "#SVM\n",
    "from sklearn.svm import SVC\n",
    "classifier_SVC=OneVsRestClassifier(SVC().fit(samples_train,target_train)) #onevsrest \n",
    "target_pred_SVC=classifier_SVC.predict(samples_test) \n",
    "accuracy_SVC=accuracy_score(target_test,target_pred_SVC) \n",
    "report_SVC=classification_report(target_test,target_pred_SVC)\n",
    "lines_SVC = report_SVC.split('\\n')\n",
    "NewLines_SVC=lines_SVC[74].split(' ')\n",
    "Logistic_precision_SVC=float(NewLines_SVC[9])\n",
    "Logistic_recall_SVC=float(NewLines_SVC[15])\n",
    "Logistic_f1score_SVC=float(NewLines_SVC[21])\n",
    "print ('the SVC accuracy score is',accuracy_SVC)\n",
    "print(\"the SVC precision is\",Logistic_precision_SVC)\n",
    "print(\"the SVC recall is\",Logistic_recall_SVC)\n",
    "print(\"the SVC f1score is\",Logistic_f1score_SVC,'\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#multibars\n",
    "df=pd.DataFrame([[accuracy_SL,accuracy_SL_R,accuracy_AD,accuracy_NB,accuracy_SVC],[Logistic_precision_SL,Logistic_precision_RF,Logistic_precision_AD,Logistic_precision_NB,Logistic_precision_SVC],[Logistic_recall_SL,Logistic_recall_RF,Logistic_recall_AD,Logistic_recall_NB,Logistic_recall_SVC],[Logistic_f1score_SL,Logistic_f1score_RF,Logistic_f1score_AD,Logistic_f1score_NB,Logistic_f1score_SVC]],index=['accuracy','precision','recall','f1score'],columns=['logistic','randomforest','Adaboost','bayes','svm'])\n",
    "fig = plt.figure() # Create matplotlib figure\n",
    "ax = fig.add_subplot(111) # Create matplotlib axes\n",
    "df.logistic.plot(kind='bar', color='red', ax=ax, width=0.1, position=0)\n",
    "df.randomforest.plot(kind='bar', color='blue', ax=ax, width=0.1, position=-1)\n",
    "df.Adaboost.plot(kind='bar', color='green', ax=ax, width=0.1, position=-2)\n",
    "df.bayes.plot(kind='bar', color='yellow', ax=ax, width=0.1, position=-3)\n",
    "df.svm.plot(kind='bar', color='gray', ax=ax, width=0.1, position=-4)\n",
    "ax.set_ylabel('percentage')\n",
    "ax.set_xticklabels(ax.xaxis.get_majorticklabels(), rotation=0)\n",
    "#ax.legend(())\n",
    "plt.legend(['logistic','randomforest','AdaBoost','bayes','svm'],loc='upper right',fontsize=8)\n",
    "plt.title('Multibars')\n",
    "#plt.show()\n",
    "plt.savefig('multibars.tiff')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
